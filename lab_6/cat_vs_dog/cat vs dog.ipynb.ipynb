{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nimport sys\nimport datetime\nimport glob as glob\nimport numpy as np\nimport cv2\nimport keras\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.optimizers import SGD\nimport tensorflow\nfrom scipy.interpolate import spline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"keras.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34c771b9e0a8cd330f0e085642762640b89f7410"},"cell_type":"code","source":"tensorflow.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a458f418c71c745a638bf98ff96eb663422caa2","collapsed":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = 'nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86bfdd91c20ec52fc0b841e7cd8f439ed0b17c14"},"cell_type":"code","source":"img = load_img('../input/cat-and-dog/training_set/training_set/cats/cat.1.jpg')\nplt.figure(figsize = (3,3))\nplt.imshow(img)\nplt.axis('off')\nplt.title('Nimesh Cat')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb5f512b3d675704470d6815630f796858822ad6","collapsed":true},"cell_type":"code","source":"x = img_to_array(img)\nx2 = x.reshape((1,) + x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5d1d05a8eca038e08e10d6d480a5cb2ef1735ab"},"cell_type":"code","source":"i = 0\nfig = plt.figure(figsize = (6,6))\nplt.title('Pre-processed')\nfor batch in datagen.flow(x2, batch_size = 1):\n    i += 1\n    if i > 9:\n        break\n    temp = batch.reshape(x.shape)\n    plt.subplot(3, 3, i)\n    plt.imshow(temp.astype('uint8'))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e7cfa35a7ca5f219618e43b1be45efb37cee387"},"cell_type":"code","source":"img = load_img('../input/cat-and-dog/training_set/training_set/dogs/dog.1.jpg')\nplt.figure(figsize = (3,3))\nplt.imshow(img)\nplt.axis('off')\nplt.title('Nimesh Dog')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b37f285f923403c1bdebab7763e2d95420060184"},"cell_type":"code","source":"# default settings\nimg_width, img_height = 224, 224\n\ntrain_dir = '../input/cat-and-dog/training_set/training_set'\nvalidate_dir = '../input/cat-and-dog/test_set/test_set/'\nnb_epochs = 2\nbatch_size = 1\nnb_classes = len(glob.glob(train_dir + '/*'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c303db59a3a20877418b90e9732cfa4ab0caf62"},"cell_type":"code","source":"# get number of images in training directory\nnb_train_samples = 0\nfor r, dirs, files in os.walk(train_dir):\n    for dr in dirs:\n        nb_train_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\nprint(nb_train_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb0374d2fdcef13abf2d99749a38e8d76f99f8f6"},"cell_type":"code","source":"# get number of images in validation directory\nnb_validate_samples = 0\nfor r, dirs, files in os.walk(validate_dir):\n    for dr in dirs:\n        nb_validate_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\nprint(nb_validate_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c869ca401136fadad6ea04b7a0d0567cbf5009ba"},"cell_type":"code","source":"\n# data pre-processing for training\ntrain_datagen =  ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7e899352175a9a143330658a3cd9b99facb53604"},"cell_type":"code","source":"# data pre-processing for validation\nvalidate_datagen =  ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"178d9471145509bc7ee581c363dae78716a4c744"},"cell_type":"code","source":"# generate and store training data\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (img_width, img_height),\n    batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55b3b6efa80a7b8034d4875bbd9c4bc345004a03"},"cell_type":"code","source":"\n# generate and store validation data\nvalidate_generator = validate_datagen.flow_from_directory(\n    validate_dir,\n    target_size = (img_width, img_height),\n    batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7160d7eb816109a54ca5184fd8191408e8f1632a"},"cell_type":"code","source":"# this will copy the pretrained weights to our kernel\n!mkdir ~/.keras\n!mkdir ~/.keras/models\n!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cace34f3ad0e3394e0ae6d48eb15cece594cd825"},"cell_type":"code","source":"# set up transfer learning on pre-trained ImageNet VGG16 model - remove fully connected layer and replace\n# with softmax for classifying 10 classes\nvgg16_model = VGG16(weights = 'imagenet', include_top = False)\nx = vgg16_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(nb_classes, activation = 'softmax')(x)\nmodel = Model(input = vgg16_model.input, output = predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9e5b4a3f2bc79311fe526aa2a393680b37abdaa3"},"cell_type":"code","source":"# freeze all layers of the pre-trained model\nfor layer in vgg16_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f14f821f56415f7788ba86afd55870e5d8fbc4cf"},"cell_type":"code","source":"# compile the new model using a RMSProp optimizer\nmodel.compile(optimizer = 'rmsprop',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5f349a5bf0f00a2cbec5cce11fca5279e5861ec"},"cell_type":"code","source":"# fit the model, log the results and the training time\nnow = datetime.datetime.now\nt = now()\ntransfer_learning_history = model.fit_generator(\n    train_generator,\n    nb_epoch = nb_epochs,\n    samples_per_epoch = nb_train_samples,\n    validation_data = validate_generator,\n    nb_val_samples = nb_validate_samples,\n    class_weight='auto')\nprint('Training time: %s' % (now() - t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"095a5d675f4369c9773a883a4e2205270f1019d2"},"cell_type":"code","source":"# evaluate the performance the new model and report the results\nscore = model.evaluate_generator(validate_generator, nb_validate_samples/batch_size)\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8960f81439c3f940602bb3f4e92a226a3f060c9b"},"cell_type":"code","source":"# save transfer learning model for offline prediction purposes\nmodel.save('dogsandcat_vgg16_model_tl.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e79fe61de3369c899311df81d7d54df798b35d4"},"cell_type":"code","source":"xfer_acc = transfer_learning_history.history['acc']\nval_acc = transfer_learning_history.history['val_acc']\nxfer_loss = transfer_learning_history.history['loss']\nval_loss = transfer_learning_history.history['val_loss']\nepochs = range(len(xfer_acc))\n\nx = np.array(epochs)\ny = np.array(xfer_acc)\nx_smooth = np.linspace(x.min(), x.max(), 500)\ny_smooth = spline(x, y, x_smooth)\nplt.plot(x_smooth, y_smooth, 'r-', label = 'Training')\n\nx1 = np.array(epochs)\ny1 = np.array(val_acc)\nx1_smooth = np.linspace(x1.min(), x1.max(), 500)\ny1_smooth = spline(x1, y1, x1_smooth)\n\nplt.plot(x1_smooth, y1_smooth, 'g-', label = 'Validation')\nplt.title('Transfer Learning - Training and Validation Accuracy')\nplt.legend(loc = 'lower left', fontsize = 9)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.ylim(0,1.05)\n\nplt.figure()\nx = np.array(epochs)\ny = np.array(xfer_loss)\nx_smooth = np.linspace(x.min(), x.max(), 500)\ny_smooth = spline(x, y, x_smooth)\nplt.plot(x_smooth, y_smooth, 'r-', label = 'Training')\n\nx1 = np.array(epochs)\ny1 = np.array(val_loss)\nx1_smooth = np.linspace(x1.min(), x1.max(), 500)\ny1_smooth = spline(x1, y1, x1_smooth)\n\nplt.plot(x1_smooth, y1_smooth, 'g-', label = 'Validation')\nplt.title('Transfer Learning - Training and Validation Loss')\nplt.legend(loc = 'upper right', fontsize = 9)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.ylim(0,max(y1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4a20feadec64f54681196895feb70bf3d019ddd"},"cell_type":"code","source":"validate_generator.total_batches_seen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14c16fff75a6aea0dca627a108cb61119f559fa9","collapsed":true},"cell_type":"code","source":"predict_files = glob.glob(\"../input/cat-and-dog/test_set/test_set/cats/*.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ea29365957ffae15cef3753d0fb2cd761b491e5","collapsed":true},"cell_type":"code","source":"im = cv2.imread(predict_files[0])\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nim = cv2.resize(im, (256, 256)).astype(np.float32)\nim = np.expand_dims(im, axis = 0)/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"313077631287dc87a25fb113ebb1ca3f2489b66b","collapsed":true},"cell_type":"code","source":"\npredictor, image_id = [], []\nfor i in predict_files:\n    im = cv2.imread(i)\n    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (256, 256)).astype(np.float32) / 255.0\n    im = np.expand_dims(im, axis =0)\n    outcome = [np.argmax(model.predict(im))]\n    predictor.extend(list(outcome))\n    image_id.extend([i.rsplit(\"\\\\\")[-1]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d19ed403ba48904d7697e7ba51674dd21bd6f3d"},"cell_type":"code","source":"final = pd.DataFrame()\nfinal[\"id\"] = image_id\nfinal[\"Cats\"] = predictor \nfinal.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9c0c68515b341c3e21423331adfa8cff9edba621"},"cell_type":"code","source":"classes = train_generator.class_indices\nclasses = {value : key for key, value in classes.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c974ebcedb12172eda2b2f7074f13d005475c46"},"cell_type":"code","source":"final[\"Cats\"] = final[\"Cats\"].apply(lambda x: classes[x])\nfinal.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1e5aa96010265087dff5374fa7a147fdd38d6a2"},"cell_type":"code","source":"final.to_csv(\"csv/dogsandcats_with_pretrained_vgg16_model_tl_test.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6fcb6a37f96851c8c39c1107f5de7146a6247b0e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}